{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Feru34/Deep_Learning/blob/main/Talleres/Taller%202/Taller_2_%7BRueda_Felipe%7D_%7BMijares_Alfredo%7D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/fcastellanosp/MINE-4210_202420_ADL/blob/main/Talleres/Taller%202/MINE4210_ADL2024_Taller2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "14quiOGQcZvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Logo ADL](https://github.com/fcastellanosp/MINE-4210_202420_ADL/blob/main/Laboratorios/logo_adl.png?raw=true)"
      ],
      "metadata": {
        "id": "K3r7qAgDcWcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Taller 2**\n",
        "\n",
        "- **Integrante 1:** Felipe Rueda\n",
        "- **Integrante 2:**"
      ],
      "metadata": {
        "id": "5ojYaeubc6-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bangladesh es una de los pa√≠ses con m√°s tr√°fico en el mundo. All√≠ se encuentran algunas particularidades como los *rickshaw*, que son veh√≠culos de 2 ruedas impulsados por una persona.\n",
        "\n",
        "Los estudios indican que alrededos de 3.000 personas fallecen al a√±o a causa de accidentes de tr√°nsito.\n",
        "\n",
        "Como consultor del sector de transporte, la organizaci√≥n ha procesado alrededor de 20.000 im√°genes etiquetadas con informaci√≥n de objetos que pertenecen a las siguientes 13 clases:\n",
        "\n",
        "* person\n",
        "* rickshaw\n",
        "* rickshaw van\n",
        "* auto rickshaw\n",
        "* truck\n",
        "* pickup truck\n",
        "* private car\n",
        "* motorcycle\n",
        "* bicycle\n",
        "* bus\n",
        "* micro bus\n",
        "* covered van\n",
        "* human hauler\n",
        "\n",
        "Han sido contratados para buscar un proceso que permita acelerar el entendimiento de esta problem√°tica, para el cu√°l le solicitan construir un modelo de detecci√≥n de objetos que permita identificar los diferentes actores viales.\n",
        "\n",
        "La informaci√≥n etiquetada se encuentra en  \"[Bangladesh traffic](https://www.kaggle.com/datasets/hasibzunair/rsud20k-bangladesh-road-scene-understanding)\"."
      ],
      "metadata": {
        "id": "vjTi178bc8eY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preguntas:**\n",
        "\n",
        "1.   Construir una red neuronal de detecci√≥n de objetos usando un modelo pre-entrenado. Recuerden ser descriptivos en el Preprocesamiento de Datos, Utilizaci√≥n de Modelos Pre-entrenados, Evaluaci√≥n de Rendimiento y b√∫squeda de hiperpar√°metros.\n",
        "\n",
        "2.  Proporcionar algunos ejemplos de detecci√≥n de objetos con la red entrenada y lo comparen con la imagen con los datos anotados. Traten de usar im√°genes con 1 objeto asi como im√°genes con varios objetos.\n",
        "\n",
        "3.  Investigar la m√©trica mAP y c√≥mo la interpreta para la red entrenada.\n",
        "\n",
        "4. Calcular el n√∫mero de escenarios (im√°genes) que involucran personas en el conjunto de prueba."
      ],
      "metadata": {
        "id": "Wc7LjhfHcQ67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Notas Importantes:**\n",
        "- Pueden usar la versi√≥n de Yolo del laboratorio u otra distinta.\n",
        "- El archivo a presentar debe ser en formato .ipynb o HTML ya ejecutado. Celda que no est√© ejecutada no se podr√° evaluar.\n",
        "- El nombre del archivo debe ser `Taller_2_{Apellido_Nombre}_{Apellido_Nombre}` de cada integrante respectivamente."
      ],
      "metadata": {
        "id": "bKrrPdPKdHPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Construir una red neuronal de detecci√≥n de objetos usando un modelo pre-entrenado"
      ],
      "metadata": {
        "id": "eYS9ACzr8b--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizaci√≥n de librer√≠as"
      ],
      "metadata": {
        "id": "iq9zNro1-tU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install ultralytics==8.0.196\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "5v_GfHTE9v3g",
        "outputId": "03b2b31a-5137-40f6-963d-f9f09288a907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.196 üöÄ Python-3.10.12 torch-2.4.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 33.0/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import random\n",
        "import re\n",
        "import shutil\n",
        "\n",
        "#Visualizaci√≥n de datos\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import display, Image\n",
        "\n",
        "from numpy import asarray\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "ZSQWVArM9x-W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "-YJLLbGX90Se",
        "outputId": "95fe6d52-f4a3-4d8a-da03-ecc0b32b6644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de datos"
      ],
      "metadata": {
        "id": "jAhcZTHa8hc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para tener un mejor detalle sobre el comportamiento de la informaci√≥n, la organizaci√≥n ha dispuesto la informaci√≥n de la siguiente forma:\n",
        "\n",
        "```python\n",
        "Multi-Class Animal Detection.v1-yolov8.zip/\n",
        "  train/\n",
        "    images/\n",
        "      a_image_1.png\n",
        "      a_image_2.jpg\n",
        "      .......    \n",
        "    labels/\n",
        "      a_image_1.txt\n",
        "      a_image_2.txt\n",
        "      .......\n",
        "  valid/\n",
        "    images/\n",
        "      b_image_1.png\n",
        "      b_image_2.jpg\n",
        "      .......    \n",
        "    labels/\n",
        "      b_image_1.txt\n",
        "      b_image_2.txt\n",
        "      .......\n",
        "  test/\n",
        "    images/\n",
        "      c_image_1.png\n",
        "      c_image_2.jpg\n",
        "      .......    \n",
        "    labels/\n",
        "      c_image_1.txt\n",
        "      c_image_2.txt\n",
        "      .......\n",
        "```"
      ],
      "metadata": {
        "id": "9nnRvdLlCe1p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Par√°metros generales y carga de la informaci√≥n"
      ],
      "metadata": {
        "id": "bTaG5OTzB7GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_seed = 19 #Semilla para reproducibilidad\n",
        "IMG_EXT = ['.jpg', '.jpeg', '.png', '.bmp'] #Extensiones v√°lidas de imagen\n",
        "TEXT_EXT = '.txt'\n",
        "YOLO_VERSION = 'yolov8'"
      ],
      "metadata": {
        "id": "-6PBcYrB_Dyx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(my_seed)"
      ],
      "metadata": {
        "id": "PrsYU1U5Au3L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuraci√≥n del entorno de kaggle.\n",
        "\n",
        "Verificamos la conectividad con kaggle, usando un comando para ver una previsualizaci√≥n de datasets:"
      ],
      "metadata": {
        "id": "3xI4N_vhB-AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lha kaggle.json\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "bv7bpqBCAwkU",
        "outputId": "fc8f3703-8b53-4503-ba83-c3d90ea286e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'kaggle.json': No such file or directory\n",
            "mkdir: cannot create directory ‚Äò/root/.kaggle‚Äô: File exists\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos la conectividad con kaggle, usando un comando para ver una previsualizaci√≥n de datasets:"
      ],
      "metadata": {
        "id": "jeaU31OwCCrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets list"
      ],
      "metadata": {
        "id": "QoQ-Pyk-A1_6",
        "outputId": "73807fbc-3f53-4438-96e7-f462f166dcf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 7, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 407, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method. See setup instructions at https://github.com/Kaggle/kaggle-api/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez hemos asegurado la conectividad, procedemos a realizar el proceso de descarga de la informaci√≥n del negocio."
      ],
      "metadata": {
        "id": "0Opix18FCGI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle datasets download -d hasibzunair/rsud20k-bangladesh-road-scene-understanding"
      ],
      "metadata": {
        "id": "9gJYF6CdA830",
        "outputId": "fdbd987d-2938-445a-c9d4-ab39fcf56e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-12-b3e26eb438d0>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-b3e26eb438d0>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    kaggle datasets download -d hasibzunair/rsud20k-bangladesh-road-scene-understanding\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la informaci√≥n que vamos a descomprimir, es necesario crear un un directorio para que el contenido del archivo zip, se encuentre all√≠. Para este prop√≥sito, vamos a crear unas variables de manejo de archivos:"
      ],
      "metadata": {
        "id": "ZH3IdUjLCKr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR = '/content'\n",
        "DATASET_NAME = 'multiclass-animal-detection'\n",
        "SUB_DATASET_NAME = 'Multi-Class Animal Detection.v1-yolov8'"
      ],
      "metadata": {
        "id": "xYjIauVoBsQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos ahora a generar una previsualizaci√≥n del comando de descompresi√≥n del archivo zip:"
      ],
      "metadata": {
        "id": "o_Vgu2zMCQ-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"!unzip {DATASET_NAME}.zip -d {ROOT_DIR}/{DATASET_NAME}\")"
      ],
      "metadata": {
        "id": "N54_v8SFBuxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora si vamos a consolidar el bloque de comandos con todos los pasos para la descompresi√≥n del archivo zip:"
      ],
      "metadata": {
        "id": "Zepl5nIRCOJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {ROOT_DIR}\n",
        "!mkdir /{DATASET_NAME}\n",
        "!unzip {DATASET_NAME}.zip -d {ROOT_DIR}/{DATASET_NAME}"
      ],
      "metadata": {
        "id": "S6Tf_PzBBv_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizaci√≥n de Modelos Pre-entrenados"
      ],
      "metadata": {
        "id": "I5k3VgOD8hDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluaci√≥n de Rendimiento"
      ],
      "metadata": {
        "id": "In9CeXfs8wzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B√∫squeda de hiperpar√°metros"
      ],
      "metadata": {
        "id": "aO0EnWHe85cC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplos de detecci√≥n de objetos con la red entrenada y su respetiva comparaci√≥n"
      ],
      "metadata": {
        "id": "5tX3JD7G9GNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# M√©trica mAP"
      ],
      "metadata": {
        "id": "9SgM5O7V9S6l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C√≥mo la interpreta para la red entrenada?"
      ],
      "metadata": {
        "id": "tkTJKQOO9U2j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N√∫mero de escenarios (im√°genes) que involucran personas en el conjunto de prueba"
      ],
      "metadata": {
        "id": "MBh7ho6i9iar"
      }
    }
  ]
}